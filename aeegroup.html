<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<!--<link rel="shortcut icon" href="http://stat.wharton.upenn.edu/~suw/favicon.ico" type="image/x-icon">-->
<link rel="stylesheet" href="./jemdoc.css" type="text/css">
<title>Miao Zhang - Miao's Group</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="./index.html" class="current">Home</a></div>
<div class="menu-item"><a href="./publication.html">Publication</a></div>
<div class="menu-item"><a href="./aeegroup.html">AEE Group</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
    <h1>AEE REARCH GROUP</h1>
<h2>Research Aim: (Less is More)</h2>



    <p>Our research is mainly focusing on <strong>Efficient</strong> ML/DL, including:</p>
    <ul><li><p><strong>Efficient</strong> Architectuure Design</p></li></ul>
    <p style="margin-left: 30pt;">Neural Architecture Search (NAS), Efficient Attention Design, GNN Structure Learning, Unstructured/Structured Neural Network Pruning</p>

    <ul><li><p><strong>Efficient</strong> Training</p></li></ul>
    <p style="margin-left: 30pt;">Meta-Learning, Continual Learning, Federated Learning, Knowledge Distillation, On-device Learning, Ensembling, Stacking, PEFT, MoE</p>

    <ul><li><p><strong>Efficient</strong> Inference</p></li></ul>
    <p style="margin-left: 30pt;">Model Compression, Quantization, Sparsification, Speculative Decoding, Dynamic Inference, Serving System</p>

    <p>Currently, my research interests are especially shifting to <strong>Efficient Foundation Models</strong>.</p>


    <h2> Supervision </h2>
    <p>I fortunately (co-)supervised several Ph.D. students:</p>
    <p><strong>Hongrong Cheng</strong> (University of Adelaide, Network Pruning, 2021-now)</p>
    <p><strong>Xin Zheng</strong> (Monash University, AutoML in Graph Neural Network, 2021-2023, now Lecture at Griffith University)</p>
    <p><strong>Xinle Wu</strong> (Aalborg University, Neural Architecture Search and Its Application on Time Series, 2021-now)</p>
    <p><strong>Kai Zhao</strong> (Aalborg University, Explainable Graph Neural Network on Time Series, 2021-now)</p>
    <p><strong>David Gonzalo Chaves Campos</strong> (Aalborg University, Model Compression on Time Series, 2021-now)</p>
    <p><strong>Jiaoqi Zhao</strong> (Harbin Institute of Technology (Shenzhen), Model Compression on Foundation Models, 2024-now)</p>
    <p><strong>Qianlong Xiang</strong> (Harbin Institute of Technology (Shenzhen), Efficient Diffusion Models, 2023-now)</p>
    <p><strong>Haomiao Qiu</strong> (Harbin Institute of Technology (Shenzhen), Continual Learning on the Edge, 2024-now)</p>
    <p><strong>Xiaodong Qu</strong> (Harbin Institute of Technology (Shenzhen), Distributed Machine Learning for LLMs, 2024-now)</p>



</td>
</tr>
</tbody></table>


</body></html>
